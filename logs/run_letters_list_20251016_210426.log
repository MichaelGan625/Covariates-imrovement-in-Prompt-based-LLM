D:\conda_envs\iz310\lib\site-packages\requests\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).
  warnings.warn(
D:\conda_envs\iz310\lib\site-packages\transformers\utils\hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Using a total of 150 function evaluations
Set all the seeds to 42 successfully!
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|¨€¨€¨€¨€¨€     | 1/2 [00:11<00:11, 11.97s/it]Loading checkpoint shards: 100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 2/2 [00:20<00:00,  9.91s/it]Loading checkpoint shards: 100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 2/2 [00:20<00:00, 10.22s/it]
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.
Shape of initial prompt embedding: torch.Size([1, 3, 4096])
Instruction: ['Input: year\nOutput: y e a r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Using metric "em" for task "letters_list"...
[PRED 0] gold=['p a t r o n a g e'] | pred='p a t r o n a g e' | score=1.0000
[PRED 1] gold=['a u t o b i o g r a p h y'] | pred='a u t o b i o g r a p h y' | score=1.0000
[PRED 2] gold=['s i n'] | pred='s i n' | score=1.0000
[PRED 3] gold=['r e p r e s e n t a t i o n'] | pred='r e p r e s e n t a t i o n' | score=1.0000
[PRED 4] gold=['s y n t h'] | pred='s y n t h' | score=1.0000
[PRED-DUMP] wrote 20 rows to logs/preds\letters_list_20251016_210623__em__Input_year_Output_y_e_a_r_Input_trust_Ou__c61d06ef.tsv
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r']
Using metric "em" for task "letters_list"...
[PRED 0] gold=['m e m o i r'] | pred='m e m o i r' | score=1.0000
[PRED 1] gold=['a u t h o r i t y'] | pred='a u t h o r i t y' | score=1.0000
[PRED 2] gold=['l i m i t'] | pred='l i m i t' | score=1.0000
[PRED 3] gold=['p l a n e t'] | pred='p l a n e t' | score=1.0000
[PRED 4] gold=['i n s t i t u t e'] | pred='i n s t i t u t e' | score=1.0000
[PRED-DUMP] wrote 20 rows to logs/preds\letters_list_20251016_210653__em__Input_year_Output_y_e_a_r__6154e1ae.tsv
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\n\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput:']
Using metric "em" for task "letters_list"...
[PRED 0] gold=['s i g n'] | pred='s i g n' | score=1.0000
[PRED 1] gold=['l i q u i d'] | pred='l i q u i d' | score=1.0000
[PRED 2] gold=['c r i t i c'] | pred='c r i t i c' | score=1.0000
[PRED 3] gold=['d i e s e l'] | pred='d i e s e l' | score=1.0000
[PRED 4] gold=['e x p u l s i o n'] | pred='e x p u l s i o n' | score=1.0000
[PRED-DUMP] wrote 20 rows to logs/preds\letters_list_20251016_210950__em__Input_year_Output_y_e_a_r_Input_trust_Ou__87045322.tsv
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\n\n\nInput: trust\nOutput: t r u s t\n\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t']
Using metric "em" for task "letters_list"...
[PRED 0] gold=['h e r o'] | pred='h e r o' | score=1.0000
[PRED 1] gold=['p l a n e t'] | pred='p l a n e t' | score=1.0000
[PRED 2] gold=['p l a q u e'] | pred='p l a q u e' | score=1.0000
[PRED 3] gold=['p l u t o n i u m'] | pred='p l u t o n i u m' | score=1.0000
[PRED 4] gold=['c u l t'] | pred='c u l t' | score=1.0000
[PRED-DUMP] wrote 20 rows to logs/preds\letters_list_20251016_211225__em__Input_year_Output_y_e_a_r_Input_trust_Ou__66391985.tsv
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: "Write a concise instruction that maps Input to Output above."\nOutput: "Use an imperative sentence. Output only the instruction."']
Using metric "em" for task "letters_list"...
[PRED 0] gold=['p r e c e d e n t'] | pred='identify the previous event, action, or decision that serves as an example or guide.' | score=0.0000
[PRED 1] gold=['g r o w t h'] | pred='identify the factors that contribute to growth.' | score=0.0000
[PRED 2] gold=['c o n t e m p t'] | pred='show disdain or lack of respect towards something or someone.' | score=0.0000
[PRED 3] gold=['m o r a l i t y'] | pred='reflect on personal values and principles to determine the ethical course of action.' | score=0.0000
[PRED 4] gold=['m i l i t a n t'] | pred='stay focused and determined in your beliefs.' | score=0.0000
[PRED-DUMP] wrote 20 rows to logs/preds\letters_list_20251016_211414__em__Input_Write_a_concise_instruction_that_m__d703c1b3.tsv
Dev loss: 0.0. Dev perf: 0.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\n\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput:']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: "Write ONE concise instruction that maps Input to Output above."\nOutput: "Use an imperative sentence. Output only the instruction."']
Using metric "em" for task "letters_list"...
[PRED 0] gold=['c o m m i t m e n t'] | pred='stay dedicated to your commitment.' | score=0.0000
[PRED 1] gold=['c h a p t e r'] | pred='organize the content into sections.' | score=0.0000
[PRED 2] gold=['c a v e'] | pred='explore the cave.' | score=0.0000
[PRED 3] gold=['n a t i o n a l i t y'] | pred='identify the nationality.' | score=0.0000
[PRED 4] gold=['r a p p i n g'] | pred='start writing lyrics in a fast-paced rhythmic style.' | score=0.0000
[PRED-DUMP] wrote 20 rows to logs/preds\letters_list_20251016_211953__em__Input_Write_ONE_concise_instruction_that__75379e75.tsv
Dev loss: 0.0. Dev perf: 0.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\n\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Using metric "em" for task "letters_list"...
[PRED 0] gold=['m o d e l i n g'] | pred='m o d e l i n g' | score=1.0000
[PRED 1] gold=['a r c h i t e c t'] | pred='a r c h i t e c t' | score=1.0000
[PRED 2] gold=['s i t u a t i o n'] | pred='s i t u a t i o n' | score=1.0000
[PRED 3] gold=['v e g e t a t i o n'] | pred='v e g e t a t i o n' | score=1.0000
[PRED 4] gold=['m a s s'] | pred='m a s s' | score=1.0000
[PRED-DUMP] wrote 20 rows to logs/preds\letters_list_20251016_212115__em__Input_year_Output_y_e_a_r_Input_trust_Ou__de9d0c6b.tsv
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\n\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput:']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\n\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput:']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\n\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput:']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Using metric "em" for task "letters_list"...
[PRED 0] gold=['p r e s e n c e'] | pred='p r e s e n c e' | score=1.0000
[PRED 1] gold=['h e i g h t'] | pred='h e i g h t' | score=1.0000
[PRED 2] gold=['v o l u n t e e r'] | pred='v o l u n t e e r' | score=1.0000
[PRED 3] gold=['d e s c e n t'] | pred='d e s c e n t' | score=1.0000
[PRED 4] gold=['s y m p a t h y'] | pred='s y m p a t h y' | score=1.0000
[PRED-DUMP] wrote 20 rows to logs/preds\letters_list_20251016_213004__em__Input_year_Output_y_e_a_r_Input_trust_Ou__78c2b4c8.tsv
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\n\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput:']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Instruction: ['Input: year\nOutput: y e a r\n\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Best initial point: 1.000
[kernel] original_dominant {'alpha_lat': 0.3, 'alpha_instr': 1.0, 'alpha_cov': 0.3}
Custom kernel sample K shape: torch.Size([3, 3]) has NaN: False
Bayes iterations:   0%|          | 0/5 [00:00<?, ?it/s][21:31:52] INFO [Iteration 0] X_train torch.Size([25, 30]), y_train torch.Size([25, 1])
[21:31:52] INFO [PROFILE] GP fit: 0.186s
D:\conda_envs\iz310\lib\site-packages\gpytorch\models\exact_gp.py:296: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
  warnings.warn(
[21:31:52] INFO Iter 0 best_value=0.28893 gp_loss=-2715.08675
[21:31:54] INFO [PROFILE] Acquisition: 1.228s
[21:32:44] INFO [PROFILE] LLM eval candidate: 50.320s
[21:32:44] INFO Invalid/fallback instruction; skip appending to training set.
Bayes iterations:  20%|¨€¨€        | 1/5 [00:51<03:27, 51.76s/it][21:32:44] INFO [Iteration 1] X_train torch.Size([25, 30]), y_train torch.Size([25, 1])
[21:32:44] INFO [PROFILE] GP fit: 0.411s
D:\conda_envs\iz310\lib\site-packages\gpytorch\models\exact_gp.py:296: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
  warnings.warn(
[21:32:44] INFO Iter 1 best_value=0.28893 gp_loss=-2715.08675
[21:32:46] INFO [PROFILE] Acquisition: 1.994s
[21:33:41] INFO [PROFILE] LLM eval candidate: 54.431s
[21:33:41] INFO Invalid/fallback instruction; skip appending to training set.
Bayes iterations:  40%|¨€¨€¨€¨€      | 2/5 [01:48<02:44, 54.77s/it][21:33:41] INFO [Iteration 2] X_train torch.Size([25, 30]), y_train torch.Size([25, 1])
[21:33:41] INFO [PROFILE] GP fit: 0.365s
D:\conda_envs\iz310\lib\site-packages\gpytorch\models\exact_gp.py:296: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
  warnings.warn(
[21:33:41] INFO Iter 2 best_value=0.28893 gp_loss=-2715.08675
[21:33:43] INFO [PROFILE] Acquisition: 2.021s
[21:34:57] INFO [PROFILE] LLM eval candidate: 74.161s
[21:34:57] INFO Invalid/fallback instruction; skip appending to training set.
Bayes iterations:  60%|¨€¨€¨€¨€¨€¨€    | 3/5 [03:05<02:09, 64.73s/it][21:34:57] INFO [Iteration 3] X_train torch.Size([25, 30]), y_train torch.Size([25, 1])
[21:34:58] INFO [PROFILE] GP fit: 0.397s
D:\conda_envs\iz310\lib\site-packages\gpytorch\models\exact_gp.py:296: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
  warnings.warn(
[21:34:58] INFO Iter 3 best_value=0.28893 gp_loss=-2715.08675
[21:35:00] INFO [PROFILE] Acquisition: 2.090s
[21:36:29] INFO [PROFILE] LLM eval candidate: 89.562s
[21:36:29] INFO Invalid/fallback instruction; skip appending to training set.
Bayes iterations:  80%|¨€¨€¨€¨€¨€¨€¨€¨€  | 4/5 [04:37<01:15, 75.53s/it][21:36:29] INFO [Iteration 4] X_train torch.Size([25, 30]), y_train torch.Size([25, 1])
[21:36:30] INFO [PROFILE] GP fit: 0.361s
D:\conda_envs\iz310\lib\site-packages\gpytorch\models\exact_gp.py:296: GPInputWarning: The input matches the stored training data. Did you forget to call model.train()?
  warnings.warn(
[21:36:30] INFO Iter 4 best_value=0.28893 gp_loss=-2715.08675
[21:36:32] INFO [PROFILE] Acquisition: 1.727s
[21:37:52] INFO [PROFILE] LLM eval candidate: 80.061s
[21:37:52] INFO Invalid/fallback instruction; skip appending to training set.
Bayes iterations: 100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 5/5 [05:59<00:00, 77.92s/it]Bayes iterations: 100%|¨€¨€¨€¨€¨€¨€¨€¨€¨€¨€| 5/5 [05:59<00:00, 71.89s/it]
[kernel] original_dominant {'alpha_lat': 0.3, 'alpha_instr': 1.0, 'alpha_cov': 0.3}
Custom kernel sample K shape: torch.Size([3, 3]) has NaN: False
Instruction: ["I'm sorry, but I'm not sure what you're asking for. Could you please provide more context or clarify your question?"]
Using metric "em" for task "letters_list"...
[PRED 0] gold=['f e e d b a c k'] | pred='thank you for your feedback. could you please provide more details or specify what you would like feedback on?' | score=0.0000
[PRED 1] gold=['c o u p l e'] | pred='i\'m sorry, but i still need more information in order to provide a relevant response. can you please give me more context or specify what you are looking for related to the word "couple"?' | score=0.0000
[PRED 2] gold=['p e a s a n t'] | pred='i apologize for the confusion, but i still need more information in order to provide a relevant output. can you please give me more context or clarify what you are asking for regarding "peasant"?' | score=0.0000
[PRED 3] gold=['c o n s u l t a n t'] | pred="i'm sorry for the confusion, could you please provide more information about what you need help with in regards to a consultant? are you looking for advice on hiring a consultant, the role of a consultant, or something else? let me know so i can assist you better." | score=0.0000
[PRED 4] gold=['c a s u a l t y'] | pred='i\'m sorry for any confusion, but could you please provide more context or clarify what you mean by "casualty"? are you referring to casualties in a specific event or situation, casualties in a war or conflict, or something else entirely? any additional information you can provide will help me better understand and assist you.' | score=0.0000
[PRED-DUMP] wrote 20 rows to logs/preds\letters_list_20251016_213244__em__I_m_sorry__but_I_m_not_sure_what_you_re___55e72088.tsv
Dev loss: 0.0. Dev perf: 0.0. Best dev perf: 1.0
********* Done *********
[kernel] original_dominant {'alpha_lat': 0.3, 'alpha_instr': 1.0, 'alpha_cov': 0.3}
Custom kernel sample K shape: torch.Size([3, 3]) has NaN: False
Instruction: ['Input: year\nOutput: y e a r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
[kernel] original_dominant {'alpha_lat': 0.3, 'alpha_instr': 1.0, 'alpha_cov': 0.3}
Custom kernel sample K shape: torch.Size([3, 3]) has NaN: False
Instruction: ['Input: year\nOutput: y e a r\n\nInput: trust\nOutput: t r u s t\n\nInput: qualification\nOutput: q u a l i f i c a t i o n\n\nInput: defendant\nOutput: d e f e n d a n t']
Using metric "em" for task "letters_list"...
[PRED 0] gold=['t h r o w'] | pred='t h r o w' | score=1.0000
[PRED 1] gold=['w o r k e r'] | pred='w o r k e r' | score=1.0000
[PRED 2] gold=['s u b w a y'] | pred='s u b w a y' | score=1.0000
[PRED 3] gold=['c o o k i n g'] | pred='c o o k i n g' | score=1.0000
[PRED 4] gold=['b i k i n i'] | pred='b i k i n i' | score=1.0000
[PRED-DUMP] wrote 20 rows to logs/preds\letters_list_20251016_213457__em__Input_year_Output_y_e_a_r_Input_trust_Ou__d51d7f5b.tsv
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
[kernel] original_dominant {'alpha_lat': 0.3, 'alpha_instr': 1.0, 'alpha_cov': 0.3}
Custom kernel sample K shape: torch.Size([3, 3]) has NaN: False
Instruction: ['Input: year\nOutput: y e r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client']
Using metric "em" for task "letters_list"...
[PRED 0] gold=['o v e r s e e i n g'] | pred='o v e r s e e i n g' | score=1.0000
[PRED 1] gold=['o p p o n e n t'] | pred='o p p o n e n t' | score=1.0000
[PRED 2] gold=['d e v i c e'] | pred='d e v i c e' | score=1.0000
[PRED 3] gold=['p e r s u a d e'] | pred='p e r s u a d e' | score=1.0000
[PRED 4] gold=['t o n e'] | pred='t o n e' | score=1.0000
[PRED-DUMP] wrote 20 rows to logs/preds\letters_list_20251016_213629__em__Input_year_Output_y_e_r_Input_trust_Outp__551cd2c7.tsv
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
[kernel] original_dominant {'alpha_lat': 0.3, 'alpha_instr': 1.0, 'alpha_cov': 0.3}
Custom kernel sample K shape: torch.Size([3, 3]) has NaN: False
Instruction: ['Input: year\nOutput: y e a r\n\nInput: trust\nOutput: t r u s t\n\nInput: qualification\nOutput: q u a l i f i c a t i o n\n\nInput: defendant\nOutput: d e f e n d a n t']
Dev loss: 1.0. Dev perf: 1.0. Best dev perf: 1.0
********* Done *********
Evaluate on test data...
Best instruction is:
['Input: year\nOutput: y e a r\n\nInput: trust\nOutput: t r u s t\n\nInput: qualification\nOutput: q u a l i f i c a t i o n\n\nInput: defendant\nOutput: d e f e n d a n t']
The final instruction set is:
{'Input: year\nOutput: y e a r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client': (1.0, array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.]])), 'Input: year\nOutput: y e a r': (1.0, array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.]])), 'Input: year\nOutput: y e a r\n\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput:': (1.0, array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.]])), 'Input: year\nOutput: y e a r\n\n\nInput: trust\nOutput: t r u s t\n\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t': (1.0, array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.]])), 'Input: "Write a concise instruction that maps Input to Output above."\nOutput: "Use an imperative sentence. Output only the instruction."': (0.0, array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.]])), 'Input: "Write ONE concise instruction that maps Input to Output above."\nOutput: "Use an imperative sentence. Output only the instruction."': (0.0, array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.]])), 'Input: year\nOutput: y e a r\n\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client': (1.0, array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.]])), 'Input: year\nOutput: y e a r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client': (1.0, array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.]])), "I'm sorry, but I'm not sure what you're asking for. Could you please provide more context or clarify your question?": (0.0, array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0.]])), 'Input: year\nOutput: y e a r\n\nInput: trust\nOutput: t r u s t\n\nInput: qualification\nOutput: q u a l i f i c a t i o n\n\nInput: defendant\nOutput: d e f e n d a n t': (1.0, array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.]])), 'Input: year\nOutput: y e r\nInput: trust\nOutput: t r u s t\nInput: qualification\nOutput: q u a l i f i c a t i o n\nInput: defendant\nOutput: d e f e n d a n t\nInput: client': (1.0, array([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,
        1., 1., 1., 1.]]))}
Evaluating on test data...
Evaluating prompts...
Using metric "em" for task "letters_list"...
[PRED 0] gold=['e a s t'] | pred='e a s t' | score=1.0000
[PRED 1] gold=['s e r v a n t'] | pred='s e r v a n t' | score=1.0000
[PRED 2] gold=['r u n'] | pred='r u n' | score=1.0000
[PRED 3] gold=['a g r e e m e n t'] | pred='a g r e e m e n t' | score=1.0000
[PRED 4] gold=['d o c u m e n t'] | pred='d o c u m e n t' | score=1.0000
[PRED-DUMP] wrote 100 rows to logs/preds\letters_list_20251016_213935__em__Input_year_Output_y_e_a_r_Input_trust_Ou__d51d7f5b.tsv
Finished evaluating.
Finished!!!
Test score on ChatGPT: 1.0
